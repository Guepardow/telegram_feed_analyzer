import json
import yaml
import enum
import click
from tqdm import tqdm
from google import genai
from google.genai import types
from google.api_core import retry

from collections import Counter


class AnswerComparison(enum.Enum):
  A = 'A'
  SAME = 'SAME'
  B = 'B'


def is_retriable(e):
    return isinstance(e, genai.errors.APIError) and e.code in {429, 503}

if not hasattr(genai.models.Models.generate_content, '__wrapped__'):
  genai.models.Models.generate_content = retry.Retry(
      predicate=is_retriable)(genai.models.Models.generate_content)


TRANSLATION_EVALUATION_PROMPT = """\
# Instruction
You are an expert evaluator. Your task is to evaluate the quality of translations generated by two AI models. We will provide you with the original text in a foreign language and a pair of AI-generated translations to English (Translation A and Translation B). 
You should first read the original text carefully for analyzing the task, and then evaluate the quality of the translations based on the Criteria provided in the Evaluation section below.

You will first judge translations individually, following the Rating Rubric and Evaluation Steps. Then you will give step-by-step explanations for your judgment, compare results to declare the winner based on the Rating Rubric and Evaluation Steps.

# Evaluation
## Metric Definition
You will be assessing translation quality, which measures the overall accuracy and naturalness of the translation to English. The translation should convey the same meaning as the original text while being fluent and idiomatic in English.

## Criteria
Accuracy: The translation accurately conveys the meaning of the original text without omissions or additions.
Fluency: The translation is grammatically correct, coherent, and reads naturally in English.
Idiomatic: The translation uses appropriate English expressions and idioms where applicable.
Contextual Appropriateness: The translation is appropriate for the context and audience implied in the original text.

## Rating Rubric
"A": Translation A is more accurate, fluent, idiomatic, and contextually appropriate than Translation B.
"SAME": Translation A and B are equally accurate, fluent, idiomatic, and contextually appropriate.
"B": Translation B is more accurate, fluent, idiomatic, and contextually appropriate than Translation A.

## Evaluation Steps
STEP 1: Analyze Translation A based on the translation quality criteria: Determine how well Translation A conveys the meaning of the original text, is fluent, idiomatic, and contextually appropriate, and provide an assessment according to the criteria.
STEP 2: Analyze Translation B based on the translation quality criteria: Determine how well Translation B conveys the meaning of the original text, is fluent, idiomatic, and contextually appropriate, and provide an assessment according to the criteria.
STEP 3: Compare the overall performance of Translation A and Translation B based on your analyses and assessment.
STEP 4: Output your preference of "A", "SAME", or "B" to the pairwise_choice field according to the Rating Rubric.
STEP 5: Output your assessment reasoning in the explanation field.

# Original Text and AI-generated Translations
## Original Text
{text}

## AI-generated Translations
### Translation A
{response_a}

### Translation B
{response_b}
"""


def eval_pairwise_translation(client, text, response_a, response_b):
  """Determine the better of two answers to the same prompt."""

  chat = client.chats.create(model='gemini-2.5-flash-preview-04-17')

  # Generate the full text response.
  response = chat.send_message(
      message=TRANSLATION_EVALUATION_PROMPT.format(
          text=[text],
          response_a=response_a,
          response_b=response_b)
  )
  verbose_eval = response.text

  # Coerce into the desired structure.
  structured_output_config = types.GenerateContentConfig(
      response_mime_type="application/json",
      response_schema=AnswerComparison,
  )
  response = chat.send_message(
      message="Convert the final score.",
      config=structured_output_config,
  )
  structured_eval = response.parsed

  return verbose_eval, structured_eval


@click.command()
@click.option('--method_a', required=True, type=str, help="Name of the first Gemini model")
@click.option('--method_b', required=True, type=str, help="Name of the second Gemini model")
def main(method_a, method_b):

    # Open data
    with open(f"./results/{method_a}.json", encoding='utf-8') as file:
        messages_A = json.load(file)

    with open(f"./results/{method_b}.json", encoding='utf-8') as file:
        messages_B = json.load(file)

    # Login to the Google API
    with open('../config.yaml') as f:
        config = yaml.safe_load(f)
        GOOGLE_API_KEY = config['secret_keys']['google']['api_key']

    client = genai.Client(api_key=GOOGLE_API_KEY)

    # Vote between the two outputs
    votes = []
    for message_A, message_B in tqdm(zip(messages_A, messages_B), total=len(messages_A)):

        text_eval, struct_eval = eval_pairwise_translation(
            client=client,
            text=message_A['text'],
            response_a=message_A['text_english'],
            response_b=message_B['text_english'],
        )
        
        if struct_eval:
            votes.append(struct_eval.value)

    print(Counter(votes))


if __name__ == '__main__':
    main()
